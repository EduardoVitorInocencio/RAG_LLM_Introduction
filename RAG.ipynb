{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6fd1b49",
   "metadata": {},
   "source": [
    "### **Importando as bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e154f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader # Permite carregar arquivos de texto\n",
    "from langchain_text_splitters import CharacterTextSplitter # Permite dividir o texto em partes menores\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore # Permite armazenar os vetores no Pinecone\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61d7d98",
   "metadata": {},
   "source": [
    "### **Carregar as vari√°veis de ambiente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8facb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea010c",
   "metadata": {},
   "source": [
    "### **INSTANCIAR O BANCO DE DADOS DO PINECONE**\n",
    "\n",
    "OBS: primeiro devemos criar o index no pinecone cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe7318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"rag-demo\"\n",
    "embeddings = CohereEmbeddings(\n",
    "    model=\"embed-english-v3.0\",\n",
    "    cohere_api_key=COHERE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a2f41d",
   "metadata": {},
   "source": [
    "### **Criando a mem√≥ria**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aeb771b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eduar\\AppData\\Local\\Temp\\ipykernel_19356\\515166408.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9775b397",
   "metadata": {},
   "source": [
    "### **CARREGAMENTO/INGEST√ÉO DO DOCUMENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d43344",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî•Carregando os documentos...\\n\\n\")\n",
    "\n",
    "PATH_FILE = \"data\\mediumblog1.txt\"\n",
    "loader = TextLoader(PATH_FILE)\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9dbd528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\mediumblog1.txt'}, page_content='Title: Vector Database: What is it and Why You Should Know It?\\n\\nAuthor: Ejiro Onose\\nDate: December 22, 2023\\n\\nIf 2021 was the year of graph databases, 2023 is the year of vector databases √¢‚Ç¨‚Äù Chip Huen.\\n\\nGenerative AI and Large Language Models (LLMs) have become popular, and a vector database is one of the best tools to handle LLM data. Vector databases provide the ideal infrastructure for managing the complex, high-dimensional data that LLMs produce and rely upon.\\n\\nIn this article, I√¢‚Ç¨‚Ñ¢ll explain what vector databases are, how they work, and introduce some top vector database tools.\\n\\n What is a Vector?\\nIn machine learning (ML), a vector is a collection of numerical values that represents the features of multi-dimensional objects, such as words or images. For example, a vector representing an image might contain values related to pixel intensities and color channels.\\n\\n What are Embeddings?\\nAn embedding is a technique for representing complex data (e.g., images, text, audio) as numerical vectors. These vectors capture the semantic similarity between different objects, making similar objects appear closer in vector space. Embeddings are essential in ML applications for tasks like clustering and anomaly detection, and vector databases efficiently store and query these embeddings.\\n\\nNote: An embedding is a vector representation, but not all vectors are embeddings.\\n\\n What is a Vector Database?\\nA vector database stores and manages unstructured data (e.g., text, images, audio) in high-dimensional vectors, enabling efficient retrieval of similar objects at scale. They use vector similarity search algorithms to quickly compare and retrieve data.\\n\\nVector databases are valuable in various applications, from recommender systems to supporting long-term memory in LLM applications, text understanding, and drug discovery.\\n\\n Benefits of Vector Databases\\n1. Handling Massive Data Loads: Vector databases can manage the extensive data generated by LLMs and generative AI.\\n2. Efficient Similarity Searches: Ideal for tasks like image search and content recommendation.\\n3. Integration with ML Algorithms: Allows seamless storage and retrieval of data relevant to ML models.\\n4. Handling Vector Embeddings: Superior for managing embeddings with real-time updates, security, and scalability.\\n\\n Popular Vector Databases\\nHere are some top vector database solutions:\\n\\n- Weaviate: Open-source, supports various data modalities, and integrates with popular ML frameworks.\\n- Pinecone: Fully managed, scalable, and secure; ideal for large ML applications.\\n- Chroma DB: Open-source with self-hosted options, supports in-memory and persistent storage.\\n- Qdrant: Offers disk-stored collections and supports complex query conditions.\\n- Milvus: Open-source with a distributed architecture; handles trillions of vectors and high query throughput.\\n\\n How to Choose the Right Vector Database\\nConsider the following factors:\\n- Scalability for large datasets.\\n- Performance for fast query execution.\\n- Security for robust data protection.\\n- Cost to ensure affordability.\\n- Query Interfaces for ease of interaction.\\n- Deployment Options and Integration Capabilities with existing LLM infrastructure.\\n\\nConclusion\\nVector databases are essential for building LLM applications, offering efficient management of high-dimensional data. Let me know your thoughts on the vector databases mentioned here, and feel free to share your experiences with them.\\n\\nHappy Building!\\n\\n\\nEjiro Onose\\n')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991efa8",
   "metadata": {},
   "source": [
    "### **FATIAMENTO/SPLITTING DOS DOCUMENTOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec54f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî™ Splitting the document into smaller chunks...\\n\\n\")\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "docs = text_splitter.split_documents(document)\n",
    "print(f\"Total chunks: {len(docs)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926126d",
   "metadata": {},
   "source": [
    "### **Instanciar o banco de dados**\n",
    "\n",
    "Ap√≥s a execu√ß√£o deste comando, os dados estar√£o dispon√≠veis no banco de dados cloud do Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "876ccfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "    docs,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa984b",
   "metadata": {},
   "source": [
    "### **Realizando consultas no banco de dados vetorial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f157464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0efdffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Vector Store?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
